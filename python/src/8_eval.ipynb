{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt IDs: tensor([[ 155,  497,  694,  270, 1696,  515,  210,  155, 1883,   15]])\n",
      "Output IDs: tensor([[ 155,  497,  694,  270, 1696,  515,  210,  155, 1883,   15,  157, 1883,\n",
      "          179,  275,  240,  163,  257,  531,  510,  581,   15,  311,  227,   13,\n",
      "          155,  285,  371,  294,  297,  440,  162,  157, 1883,   15,  202,  179,\n",
      "          275,  614,  162,  429,  157, 1883,   15,  118,  549,  223,   13,  215,\n",
      "         1017,   13, 1173,   15,  655,    2,  166,  262,  162,  429,  157, 1883,\n",
      "          315,  306,  157,  655,  223,   13,  215, 1360,   13,  297,    2,  166,\n",
      "          492,  592,  234,  157,  577,  794,  162,  429,  157, 1883,  289,  118,\n",
      "          549,  163,  157,  655,  319,  162,  157, 1883,   15,  189,  278,  157,\n",
      "         1883,  179,  275,  240,  163,  275,  627,   15,  297,  223,   13,  215,\n",
      "         1082,   13, 1173,   15,  655,    2,  530,  323,  157,  577, 1883,  800,\n",
      "          306,  118,  549,  163,  157,  655,  576,  447,  304,   15,  189,  368,\n",
      "          348,  413,  227,   15,  297,  179,  275,  273,  162,  390,  155,  435,\n",
      "          252,   15,  163,  157,  655,  179,  273,  162,  390,  155,  435,  252,\n",
      "           15,  118,    0]])\n",
      "Output Text:  a chinese dragon lived in a cave. the cave was very big and had many things inside. one day, a little girl named lily came to the cave. she was very excited to see the cave.\n",
      "lily said, \"hello, mr. bear! i want to see the cave too!\" the bear said, \"okay, lily! i will show you the best way to see the cave.\"\n",
      "lily and the bear went to the cave. they saw the cave was very big and very pretty. lily said, \"wow, mr. bear! this is the best cave ever!\"\n",
      "lily and the bear became good friends. they played together every day. lily was very happy to have a new friend. and the bear was happy to have a new friend.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from model import WSConfig, WSModel\n",
    "from transformers import PreTrainedTokenizerFast, GenerationConfig\n",
    "\n",
    "hf_model_dir = \"tinystories/runs/ts-1-512seqlen/hfmodel\"\n",
    "\n",
    "test_config = WSConfig.from_pretrained(hf_model_dir)\n",
    "test_model = WSModel.from_pretrained(hf_model_dir, config=test_config)\n",
    "test_tokenizer = PreTrainedTokenizerFast.from_pretrained(hf_model_dir)\n",
    "\n",
    "prompt = \"A Chinese dragon lived in a cave.\"\n",
    "prompt_ids = test_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "print(\"Prompt IDs:\", prompt_ids)\n",
    "\n",
    "\n",
    "output_ids = test_model.generate(\n",
    "    prompt_ids, eos_token_id=test_tokenizer.eos_token_id, max_new_tokens=300\n",
    ")\n",
    "print(\"Output IDs:\", output_ids)\n",
    "\n",
    "output_text = test_tokenizer.decode(output_ids[0])\n",
    "print(\"Output Text:\", output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt IDs: tensor([[ 251, 1782,  560,  346,  313, 5014, 5218,   12,  258, 1513]])\n",
      "Output IDs: tensor([[ 251, 1782,  560,  346,  313, 5014, 5218,   12,  258, 1513,  318,  208,\n",
      "         1181, 3435,  254,  991,  258,  391, 2626,   14,  258,  404,  612,  813,\n",
      "          251,  540,  208, 1181, 3435,  254,  991,  258,  391, 2626,   14,  352,\n",
      "          154,  269,  258,  391,  208, 1181, 3435,  254,  991,  258,  391, 2626,\n",
      "           12,  258,  404,  680,  208,  686,  254,  313, 2521,   14,  154,  269,\n",
      "          258,  391,  208, 1440,   12,  258,  404,  680,  208,  686,  254,  313,\n",
      "         2521,   14,  154,  269,  258,  391,  208, 1440,   12,  258,  404, 1605,\n",
      "          284,  208, 1440,  326, 1699, 2396,   14,  154,  269,  258,  391,  208,\n",
      "         1440,   12,  258,  404, 1605,  284,  208, 1440,  326, 1699, 2396,   14,\n",
      "          154,  269,  258,  391,  208, 1440,   12,  258,  404, 1605,  284,  208,\n",
      "         1440,  326, 1699, 2396,   14,  154,  269,  258,  391,  208, 1440,   12,\n",
      "          258,  404, 1605,  284,  208, 1440,  326, 1699, 2396,   14,  154,  269,\n",
      "          258,  391,  208, 1440,   12,  258,  404, 1605,  284,  208, 1440,  326,\n",
      "         1699, 2396,   14,  154,  269,  258,  391,  208, 1440,   12,  258,  404,\n",
      "         1605,  284,  208, 1440,  326, 1699, 2396,   14,  154,  269,  258,  391,\n",
      "          208, 1440,   12,  258,  404, 1605,  284,  208, 1440,  326, 1699, 2396,\n",
      "           14,  154,  269,  258,  391,  208, 1440,   12,  258,  404, 1605,  284,\n",
      "          208, 1440,  326, 1699, 2396,   14]])\n",
      "Output Text:  to break up with your girlfriend, you must be a good idea of what you are doing. you can also try to get a good idea of what you are doing.\n",
      "\n",
      "\n",
      "if you are a good idea of what you are doing, you can make a list of your friends.\n",
      "if you are a friend, you can make a list of your friends.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPTNeoXForCausalLM, GPTNeoXConfig\n",
    "\n",
    "hf_model_dir = \"gpt-neox/huggingface_model/\"\n",
    "\n",
    "test_config = GPTNeoXConfig.from_pretrained(hf_model_dir)\n",
    "test_model = GPTNeoXForCausalLM.from_pretrained(hf_model_dir, config=test_config)\n",
    "test_tokenizer = PreTrainedTokenizerFast.from_pretrained(hf_model_dir)\n",
    "\n",
    "prompt = \"To break up with your girlfriend, you must\"\n",
    "prompt_ids = test_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "print(\"Prompt IDs:\", prompt_ids)\n",
    "\n",
    "\n",
    "output_ids = test_model.generate(prompt_ids, max_new_tokens=200)\n",
    "print(\"Output IDs:\", output_ids)\n",
    "\n",
    "output_text = test_tokenizer.decode(output_ids[0])\n",
    "print(\"Output Text:\", output_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
