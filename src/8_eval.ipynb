{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt IDs: tensor([[ 153,  488,  718,  262, 1669,  510,  214,  153, 1861,   14]])\n",
      "Output IDs: tensor([[ 153,  488,  718,  262, 1669,  510,  214,  153, 1861,   14,  154, 1669,\n",
      "          177,  274,  240,  161,  254,  526,  303,   14,  154, 1669,  177,  274,\n",
      "          607,  161,  421,  160,  223,  225,  154,  842,   14,  390,  226,   12,\n",
      "          154, 1669,  276,  153,  285,  368, 1577,   14,  154, 1669,  429,  228,\n",
      "           12,  203, 1155,  371,  234,  380,  367,  154,  285,  368,  222,   12,\n",
      "          203,   46,  892,  487,  336,  293,  154, 1669,  301,  160,  323,  228,\n",
      "           14, 1623, 1669,  222,   12,  203,   46,  484,  323,  234,  459,  498,\n",
      "          336,  293,  154, 1669,  161,  154,  285,  368,  393,  311,  505,  154,\n",
      "         1861,   14,  185,  393,  640,  154,  893,   12, 1099,  154,  775,   12,\n",
      "          161,  214,  154,  336,  500,   14, 1082,   12,  185,  395,  154,  336,\n",
      "          640,  153, 1731,   14,  154, 1669,  177,  263,  273,    1,  167,  222,\n",
      "           12,  203,  696,  234,   12,  285,  368,  305,  154, 1669,  450,  161,\n",
      "          222,   12,  203,  779, 1326, 1590,   14,  164,  795, 1239,  164,  355,\n",
      "          323,  293,  154,  285,  368,  450,  161,  222,   12,  203,  779, 1326,\n",
      "         1590,   12, 1133,   14, 1669,  293,  154, 1669,  161,  185,  311,  573,\n",
      "          443,  303,   14,  185,  365,  345,  408,  226,   12,  161,  154, 1669,\n",
      "          278,  251,  177,  586,  290,  160,  323,  377,   14,  161,  185,  311,\n",
      "          510,  843,  798,  571,   14,  154]])\n",
      "Output Text:  a chinese dragon lived in a cave. the dragon was very big and had many friends. the dragon was very nice and liked to play with the kids.one day, the dragon saw a little girl crying. the dragon asked her, \"why are you sad?\" the little girl said, \"i lost my toy.\" the dragon wanted to help her.the dragon said, \"i will help you find your toy.\" the dragon and the little girl looked all around the cave. they looked under the bed, behind the door, and in the toy box. finally, they found the toy under a bush. the dragon was so happy! he said, \"thank you, little girl!\" the dragon smiled and said, \"you're welcome. i'm glad i could help.\" the little girl smiled and said, \"you're welcome, mr. dragon.\" the dragon and they all became good friends. they played together every day, and the dragon's mom was always there to help them. and they all lived happily ever after. the\n"
     ]
    }
   ],
   "source": [
    "from model import WSConfig, WSModel\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "hf_model_dir = \"tinystories/hfmodel/\"\n",
    "\n",
    "test_config = WSConfig.from_pretrained(hf_model_dir)\n",
    "test_model = WSModel.from_pretrained(hf_model_dir, config=test_config)\n",
    "test_tokenizer = PreTrainedTokenizerFast.from_pretrained(hf_model_dir)\n",
    "\n",
    "prompt = \"A Chinese dragon lived in a cave.\"\n",
    "prompt_ids = test_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "print(\"Prompt IDs:\", prompt_ids)\n",
    "\n",
    "\n",
    "output_ids = test_model.generate(prompt_ids, max_new_tokens=200)\n",
    "print(\"Output IDs:\", output_ids)\n",
    "\n",
    "output_text = test_tokenizer.decode(output_ids[0])\n",
    "print(\"Output Text:\", output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt IDs: tensor([[ 251, 1782,  560,  346,  313, 5014, 5218,   12,  258, 1513]])\n",
      "Output IDs: tensor([[ 251, 1782,  560,  346,  313, 5014, 5218,   12,  258, 1513,  318,  208,\n",
      "         1181, 3435,  254,  991,  258,  391, 2626,   14,  258,  404,  612,  813,\n",
      "          251,  540,  208, 1181, 3435,  254,  991,  258,  391, 2626,   14,  352,\n",
      "          154,  269,  258,  391,  208, 1181, 3435,  254,  991,  258,  391, 2626,\n",
      "           12,  258,  404,  680,  208,  686,  254,  313, 2521,   14,  154,  269,\n",
      "          258,  391,  208, 1440,   12,  258,  404,  680,  208,  686,  254,  313,\n",
      "         2521,   14,  154,  269,  258,  391,  208, 1440,   12,  258,  404, 1605,\n",
      "          284,  208, 1440,  326, 1699, 2396,   14,  154,  269,  258,  391,  208,\n",
      "         1440,   12,  258,  404, 1605,  284,  208, 1440,  326, 1699, 2396,   14,\n",
      "          154,  269,  258,  391,  208, 1440,   12,  258,  404, 1605,  284,  208,\n",
      "         1440,  326, 1699, 2396,   14,  154,  269,  258,  391,  208, 1440,   12,\n",
      "          258,  404, 1605,  284,  208, 1440,  326, 1699, 2396,   14,  154,  269,\n",
      "          258,  391,  208, 1440,   12,  258,  404, 1605,  284,  208, 1440,  326,\n",
      "         1699, 2396,   14,  154,  269,  258,  391,  208, 1440,   12,  258,  404,\n",
      "         1605,  284,  208, 1440,  326, 1699, 2396,   14,  154,  269,  258,  391,\n",
      "          208, 1440,   12,  258,  404, 1605,  284,  208, 1440,  326, 1699, 2396,\n",
      "           14,  154,  269,  258,  391,  208, 1440,   12,  258,  404, 1605,  284,\n",
      "          208, 1440,  326, 1699, 2396,   14]])\n",
      "Output Text:  to break up with your girlfriend, you must be a good idea of what you are doing. you can also try to get a good idea of what you are doing.\n",
      "\n",
      "\n",
      "if you are a good idea of what you are doing, you can make a list of your friends.\n",
      "if you are a friend, you can make a list of your friends.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n",
      "if you are a friend, you can ask for a friend or family member.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPTNeoXForCausalLM, GPTNeoXConfig\n",
    "\n",
    "hf_model_dir = \"gpt-neox/huggingface_model/\"\n",
    "\n",
    "test_config = GPTNeoXConfig.from_pretrained(hf_model_dir)\n",
    "test_model = GPTNeoXForCausalLM.from_pretrained(hf_model_dir, config=test_config)\n",
    "test_tokenizer = PreTrainedTokenizerFast.from_pretrained(hf_model_dir)\n",
    "\n",
    "prompt = \"To break up with your girlfriend, you must\"\n",
    "prompt_ids = test_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "print(\"Prompt IDs:\", prompt_ids)\n",
    "\n",
    "\n",
    "output_ids = test_model.generate(prompt_ids, max_new_tokens=200)\n",
    "print(\"Output IDs:\", output_ids)\n",
    "\n",
    "output_text = test_tokenizer.decode(output_ids[0])\n",
    "print(\"Output Text:\", output_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
